# -*- coding: utf-8 -*-
"""vip-project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f6JNRcMNmqSXr6lru2gfs07H6LB4LA3K
"""

import cv2
import numpy as np
import time
import ipywidgets.widgets as widgets

from jetbotmini import Robot
from jetbotmini import Camera
from jetbotmini import bgr8_to_jpeg

#젯봇 미니 모듈
camera = Camera.instance(width=640, height=360)
robot = Robot()

#
def saturation(value):
    if value > 255:
        value = 255
    return value

#카메라에 맞춰서 영역 자르기기
def ROI(img, vertices1):
    mask = np.zeros_like(img)
    if len(img.shape) > 2:
        color = (255, 255, 255)
    else:
        color = 255

    cv2.fillPoly(mask, vertices1, color)

    roi_image = cv2.bitwise_and(img, mask)
    return roi_image

image = widgets.Image(format='jpeg', width=640, height=360)
display(image)

#차선 인식(Line Detect)
def Detect(change):
    src = camera.value
    gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (3, 3), 0)
    canny = cv2.Canny(blur, 50, 200, None, 3)

    height = canny.shape[0]
    region = np.array([[(0, height), (0, 250), (640, 250), (640, height)]])

    roi_img = ROI(canny, region)

    ccan = cv2.cvtColor(roi_img, cv2.COLOR_GRAY2BGR)
    line_img = np.zeros(
        (roi_img.shape[0], roi_img.shape[1], 3), dtype=np.uint8)
    lineP = cv2.HoughLinesP(roi_img, 1, np.pi / 180, 5, minLineLength=5, maxLineGap=10)
    line_rigth = np.empty((0, 5), int)
    line_left = np.empty((0, 5), int)
    if lineP is not None:
        line_arr2 = np.empty((len(lineP), 5), int)
        for i in range(0, len(lineP)):
            temp = 0
            l = line_arr[i][0]
            line_arr2[i] = np.append(lineP[i], np.array((np.arctan2(l[1] - l[3], l[0] - l[2]) * 180) / np.pi))
            if line_arr2[i][1] > line_arr2[i][3]:
                temp = line_arr2[i][0], line_arr2[i][1]
                line_arr2[i][0], line_arr2[i][1] = line_arr2[i][2], line_arr2[i][3]
                line_arr2[i][2], line_arr2[i][3] = temp
              #검출라인 위치에 따라서 왼쪽, 오른쪽 구분
            if line_arr2[i][0] < 320 and (abs(line_arr2[i][4]) < 170 and abs(line_arr2[i][4]) > 95):
                line_left = np.append(line_left, line_arr2[i])
            elif line_arr2[i][0] > 320 and (abs(line_arr2[i][4]) < 170 and abs(line_arr2[i][4]) > 95):
                line_right = np.append(line_right, line_arr2[i])
    line_left = line_left.reshape(int(len(line_left) / 5), 5)
    line_righr = line_righr.reshape(int(len(line_right) / 5), 5)


    #각도 구하고 이미지에 선 그리기
    try:
        line_left = line_left[line_left[:, 0].argsort()[-1]]
        degree_left = line_left[4]
        cv2.line(line_img, (line_left[0], line_left[1]), (line_left[2], line_left[3]), (255, 0, 0), 10, cv2.LINE_AA)
    except:
        degree_left = 0
    try:
        line_right = line_right[line_right[:, 0].argsort()[0]]
        degree_right = line_right[4]
        cv2.line(line_img, (line_right[0], line_right[1]), (line_right[2], line_right[3]), (255, 0, 0), 10, cv2.LINE_AA)
    except:
        degree_right = 0

    #각도에 따른 바퀴 작동
    if abs(degree_left) <= 160 or abs(degree_right) <= 160:
        if degree_left ==0 or degree_right == 0:
            if degree_left < 0 or degree_right < 0:
                robot.right_motor.value = 0.4
                print('left')

            elif degree_left > 0 or degree_right > 0:
                robot.left_motor.value = 0.4
                print('right')

        elif abs(degree_left-20) > abs(degree_right):
            robot.left_motor.value = 0.4
            print('right')

        elif abs(degree_right + 20) > abs(degree_left):
            robot.right_motor.value = 0.4
            print('left')

        else:
            robot.right_motor.value = 0.242
            robot.left_motor.value = 0.25
            print('go')
    else:
        if degree_left > 160 or degree_right > 160:
            robot.right_motor.value = 0.5
            print('strong left')
        elif degree_left < -160 or degree_right < -160:
            robot.left_motor.value = 0.5
            print('strong right')

    result_img = cv2.addWeighted(src, 1, line_img, 1, 0)
    image.value = bgr8_to_jpeg(result_img)

Detect({'new': camera.value})

camera.unobserve_all()
camera.observe(Detect, names='value')

camera.unobserve_all()
time.sleep(1.0)
robot.stop()





